{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mA5ETHXcEu3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d831644b-b2ea-46b2-dc1c-60bf0c514345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo4sNrAvE1-8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HcBlKIMFXaA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWMscoaRFaA5"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "ZIP_FILE = \"/content/drive/MyDrive/AI_Files/AIA-image-classification-6.zip\"  # Update with the actual ZIP file path\n",
        "DATA_FOLDER = \"/content/drive/MyDrive/AI_Files/dataset\"   # Folder where data will be extracted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnNnScuIFbVO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ensure Google Drive is mounted\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Extract if not already extracted\n",
        "if not os.path.exists(DATA_FOLDER):\n",
        "    with zipfile.ZipFile(ZIP_FILE, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(DATA_FOLDER)\n",
        "\n",
        "print(\" Extraction complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8MsQbllFdLo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJGPXMXVFc_4"
      },
      "outputs": [],
      "source": [
        "for root, dirs, files in os.walk(DATA_FOLDER):\n",
        "    for file in files:\n",
        "        if file.endswith(\".csv\"):\n",
        "            print(f\"Found CSV file: {os.path.join(root, file)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgvZTLi5FeQb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/AI_Files/dataset/AIA image classification/upload/images.csv\"\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(file_path):\n",
        "    print(\"✅ File found!\")\n",
        "else:\n",
        "    print(\"❌ File not found! Check the path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ11McpoFgwq"
      },
      "outputs": [],
      "source": [
        "# Assuming the CSV file is inside the extracted folder\n",
        "CSV_FILE = os.path.join(DATA_FOLDER, \"/content/drive/MyDrive/AI_Files/dataset/AIA image classification/upload/images.csv\")  # Update the actual filename\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "\n",
        "# Verify the first few rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI6KSNt9FiZ0"
      },
      "outputs": [],
      "source": [
        "IMAGE_DIR = \"/content/drive/MyDrive/AI_Files/dataset/AIA image classification/upload/images/images\"  # Update this path\n",
        "\n",
        "# Update image paths inside DataFrame\n",
        "df[\"image_path\"] = df[\"image_name\"].apply(lambda x: os.path.join(IMAGE_DIR, x))\n",
        "\n",
        "# Verify\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrh8W-rrFlR4"
      },
      "outputs": [],
      "source": [
        "# Remove rows where image does not exist\n",
        "df = df[df[\"image_path\"].apply(os.path.exists)].reset_index(drop=True)\n",
        "\n",
        "print(f\"✅ Total images after cleaning: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "836dW_3NFmoW"
      },
      "outputs": [],
      "source": [
        "# label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "\n",
        "# Split into train & validation\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"label_encoded\"], random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg0EtppTFoMm"
      },
      "outputs": [],
      "source": [
        "# data preprocessing and traing dataset\n",
        "IMG_SIZE = (224, 224)  # Image size for model\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(img_path, label):\n",
        "    img = load_img(img_path, target_size=IMG_SIZE)  # Resize image\n",
        "    img = img_to_array(img) / 255.0  # Normalize\n",
        "    return img, label\n",
        "\n",
        "# Convert DataFrame to tf.data.Dataset\n",
        "def dataframe_to_tf_dataset(df, batch_size):\n",
        "    file_paths = df[\"image_path\"].values\n",
        "    labels = df[\"label_encoded\"].values\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "    dataset = dataset.map(lambda x, y: tf.py_function(func=load_and_preprocess_image, inp=[x, y], Tout=(tf.float32, tf.int32)))\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Create train & validation datasets\n",
        "train_ds = dataframe_to_tf_dataset(train_df, BATCH_SIZE)\n",
        "val_ds = dataframe_to_tf_dataset(val_df, BATCH_SIZE)\n",
        "\n",
        "print(\"✅ Dataset ready for training!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrWtUOVHFp0a"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (224, 224)  # Image size for model\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_and_preprocess_image(img_path, label):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)  # Decodes JPEG image\n",
        "    img = tf.image.resize(img, IMG_SIZE) / 255.0  # Resize & normalize\n",
        "    return img, label\n",
        "\n",
        "def dataframe_to_tf_dataset(df, batch_size):\n",
        "    file_paths = df[\"image_path\"].values\n",
        "    labels = df[\"label_encoded\"].values.astype(np.int32)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "    def _parse_function(file_path, label):\n",
        "        img, label = tf.py_function(load_and_preprocess_image, [file_path, label], [tf.float32, tf.int32])\n",
        "        img.set_shape((*IMG_SIZE, 3))  # Explicitly setting image shape\n",
        "        label.set_shape([])  # Scalar shape for label\n",
        "        return img, label\n",
        "\n",
        "    dataset = dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Create train & validation datasets\n",
        "train_ds = dataframe_to_tf_dataset(train_df, BATCH_SIZE)\n",
        "val_ds = dataframe_to_tf_dataset(val_df, BATCH_SIZE)\n",
        "\n",
        "print(\" Dataset ready for training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j78WAjpMFrc4"
      },
      "outputs": [],
      "source": [
        "#Model Development and Compilation\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(6, activation=\"softmax\")(x)  # 6 classes\n",
        "\n",
        "# Define model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"✅ Model compiled successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN5X7BK3FtCI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxOnbmfAFs6o"
      },
      "outputs": [],
      "source": [
        "# Import necessary callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZGnBdY0FuW0"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "EPOCHS = 1\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dNv2vA5Fxs5"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "results = model.evaluate(val_ds)\n",
        "print(f\"Validation Loss: {results[0]:.4f}\")\n",
        "print(f\"Validation Accuracy: {results[1]*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UOtJMzyFzy1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEANvQbnF1Yv"
      },
      "outputs": [],
      "source": [
        "save_path = \"/content/drive/MyDrive/AI_Files/dataset/image_classification_model.keras\"\n",
        "model.save(save_path)\n",
        "print(\"Fine-tuned model saved successfully in Keras format!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jVQB5jAF32W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5wS2EQYF3pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aea3bcc-8f7e-4f43-d72a-324523ebc6b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (3.0.2)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6b160MqF5r7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b90a08-3f72-4053-8b09-fad294164ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "!ngrok config add-authtoken 2tGY0JW2AyjO8NpMuMLl3Scodih_4VZ6U3ifdsWxXzf4US6CW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZNENSN9GDnF",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "34099e49-9d94-43fa-c512-4eb6edc993f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File not found: filepath=/content/drive/MyDrive/AI_Files/dataset/image_classification_model.keras. Please ensure the file is an accessible `.keras` zip file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d5078a600731>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Load trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/AI_Files/dataset/image_classification_model.keras\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Function to preprocess and predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=/content/drive/MyDrive/AI_Files/dataset/image_classification_model.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from flask import Flask, request, jsonify, render_template\n",
        "from pyngrok import ngrok\n",
        "from werkzeug.utils import secure_filename\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Initialize Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define the upload folder\n",
        "UPLOAD_FOLDER = \"/content/drive/MyDrive/AI_Files/dataset/UPLOAD_FOLDER\"\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "app.config[\"UPLOAD_FOLDER\"] = UPLOAD_FOLDER\n",
        "\n",
        "# Load trained model\n",
        "model_path = \"/content/drive/MyDrive/AI_Files/dataset/image_classification_model.keras\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Function to preprocess and predict\n",
        "def model_predict(img_path, model):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions)\n",
        "    confidence_score = np.max(predictions) * 100\n",
        "\n",
        "    return predicted_class, confidence_score\n",
        "\n",
        "# Home Route - Serves HTML\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Flask Image Classification</title>\n",
        "    <style>\n",
        "        * {\n",
        "            font-family: Arial, sans-serif;\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            box-sizing: border-box;\n",
        "        }\n",
        "        body {\n",
        "            background: #f4f4f4;\n",
        "            display: flex;\n",
        "            justify-content: center;\n",
        "            align-items: center;\n",
        "            height: 100vh;\n",
        "            text-align: center;\n",
        "        }\n",
        "        .container {\n",
        "            background: white;\n",
        "            padding: 20px;\n",
        "            border-radius: 8px;\n",
        "            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.2);\n",
        "            width: 90%;\n",
        "            max-width: 400px;\n",
        "            position: relative;\n",
        "        }\n",
        "        h1 {\n",
        "            margin-bottom: 15px;\n",
        "        }\n",
        "        .upload-box {\n",
        "            border: 2px dashed #007BFF;\n",
        "            padding: 20px;\n",
        "            cursor: pointer;\n",
        "            display: block;\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "        input[type=\"file\"] {\n",
        "            display: none;\n",
        "        }\n",
        "        button {\n",
        "            background: #007BFF;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            padding: 10px 15px;\n",
        "            cursor: pointer;\n",
        "            margin-top: 10px;\n",
        "            width: 100%;\n",
        "            border-radius: 5px;\n",
        "            display: none;\n",
        "        }\n",
        "        .result {\n",
        "            margin-top: 15px;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .uploaded-image {\n",
        "            width: 100%;\n",
        "            max-height: 200px;\n",
        "            margin-top: 10px;\n",
        "            border-radius: 5px;\n",
        "            opacity: 0;\n",
        "            transition: opacity 2s ease-in-out;\n",
        "        }\n",
        "        .upload-success {\n",
        "            font-size: 16px;\n",
        "            color: green;\n",
        "            font-weight: bold;\n",
        "            display: none;\n",
        "            margin-top: 10px;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "    <div class=\"container\">\n",
        "        <h1>Image Classification 6 Labels</h1>\n",
        "\n",
        "        <form id=\"uploadForm\" enctype=\"multipart/form-data\">\n",
        "            <label class=\"upload-box\" id=\"uploadBox\">\n",
        "                Click to Upload Image\n",
        "                <input type=\"file\" id=\"fileInput\" name=\"file\" accept=\"image/*\" required>\n",
        "            </label>\n",
        "        </form>\n",
        "\n",
        "        <div class=\"upload-success\" id=\"uploadSuccess\">Image Uploaded Successfully!</div>\n",
        "\n",
        "        <img id=\"uploadedImage\" class=\"uploaded-image\" alt=\"Uploaded Image\">\n",
        "\n",
        "        <button type=\"submit\" id=\"uploadBtn\">Predict</button>\n",
        "\n",
        "        <div class=\"result\" id=\"result\"></div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        document.getElementById(\"fileInput\").onchange = function(event) {\n",
        "            let file = event.target.files[0];\n",
        "            if (!file) return;\n",
        "\n",
        "            // Show upload success message\n",
        "            let uploadSuccess = document.getElementById(\"uploadSuccess\");\n",
        "            uploadSuccess.style.display = \"block\";\n",
        "\n",
        "            // Display the uploaded image\n",
        "            let uploadedImage = document.getElementById(\"uploadedImage\");\n",
        "            uploadedImage.src = URL.createObjectURL(file);\n",
        "\n",
        "            // Start the fade-in effect for the image\n",
        "            setTimeout(() => {\n",
        "                uploadedImage.style.opacity = \"1\";\n",
        "            }, 1000);\n",
        "\n",
        "            // Show Predict button after image is fully visible\n",
        "            setTimeout(() => {\n",
        "                document.getElementById(\"uploadBtn\").style.display = \"block\";\n",
        "            }, 3000);\n",
        "        };\n",
        "\n",
        "        document.getElementById(\"uploadBtn\").onclick = async function(event) {\n",
        "            event.preventDefault();\n",
        "\n",
        "            let fileInput = document.getElementById(\"fileInput\");\n",
        "            let file = fileInput.files[0];\n",
        "\n",
        "            if (!file) {\n",
        "                alert(\"Please upload an image first.\");\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            let formData = new FormData();\n",
        "            formData.append(\"file\", file);\n",
        "\n",
        "            let response = await fetch(\"/predict\", {\n",
        "                method: \"POST\",\n",
        "                body: formData\n",
        "            });\n",
        "\n",
        "            let result = await response.json();\n",
        "            document.getElementById(\"result\").innerText = \"Prediction: \" + result.prediction + \" - Confidence: \" + result.confidence;\n",
        "        };\n",
        "    </script>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "# Prediction Route\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    if \"file\" not in request.files:\n",
        "        return jsonify({\"error\": \"No file uploaded\"}), 400\n",
        "\n",
        "    file = request.files[\"file\"]\n",
        "    if file.filename == \"\":\n",
        "        return jsonify({\"error\": \"No file selected\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Save the uploaded file\n",
        "        filename = secure_filename(file.filename)\n",
        "        file_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], filename)\n",
        "        file.save(file_path)\n",
        "\n",
        "        # Make a prediction\n",
        "        predicted_class, confidence_score = model_predict(file_path, model)\n",
        "\n",
        "        return jsonify({\n",
        "            \"prediction\": f\"Class {predicted_class}\",\n",
        "            \"confidence\": f\"{confidence_score:.2f}%\"\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# Start Flask with Ngrok\n",
        "if __name__ == \"__main__\":\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(\"Public URL:\", public_url)\n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2o8pnnfKt1YM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}